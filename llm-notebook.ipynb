{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea3b5333",
   "metadata": {},
   "source": [
    "This notebook with call the necessary functions to pass a data frame to an LLM and have it make suggestions for the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8c3110c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Library import for loading df\n",
    "from llm_data_checker import read_df\n",
    "\n",
    "\n",
    "#incase of error with file cache uncomment below command \n",
    "#importlib.reload(llm_data_checker)\n",
    "\n",
    "data = read_df(\"data_test/Uncleaned_DS_jobs.csv\")\n",
    "\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af013ec7",
   "metadata": {},
   "source": [
    "Run this cell to check basic stats of df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a78443a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_data_checker import df_checker\n",
    "\n",
    "check_data = df_checker(data)\n",
    "\n",
    "\n",
    "#write out the stats to external directory\n",
    "with open(\"outputs/stats.txt\", \"w\") as f:\n",
    "    for section_name, section_value in check_data.items():\n",
    "        # Write a header for this section\n",
    "        f.write(f\"===== {section_name} =====\\n\")\n",
    "        \n",
    "        # Write the actual data\n",
    "        f.write(str(section_value))\n",
    "        \n",
    "        # Add spacing\n",
    "        f.write(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e1bc84",
   "metadata": {},
   "source": [
    "Anonymiser: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc03340",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22df4487",
   "metadata": {},
   "source": [
    "Prompt builder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "918c89ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path \n",
    "\n",
    "#point to directoy holding prompt files\n",
    "framework_txt = Path(\"frameworks\")\n",
    "\n",
    "#points to the directory holding the df stats \n",
    "stats_txt = Path(\"outputs\")\n",
    "\n",
    "#read the actual files themselves\n",
    "system_template = (framework_txt / \"prompt.txt\").read_text()\n",
    "\n",
    "\n",
    "func_test_suite = (framework_txt / \"func_test_suite.txt\").read_text()\n",
    "function_format = (framework_txt / \"function_format.txt\").read_text()\n",
    "stats = (stats_txt / \"stats.txt\").read_text()\n",
    "reasoning = (framework_txt / \"reasoning.txt\").read_text()\n",
    "\n",
    "\n",
    "#build the actual prompt \n",
    "\n",
    "prompt = system_template.format(\n",
    "    func_test_suite=func_test_suite,\n",
    "    function_format=function_format,\n",
    "    stats=stats,\n",
    "    reasoning=reasoning,\n",
    ")\n",
    "\n",
    "#write out the stats to external directory\n",
    "with open(\"final_prompt/combined_prompt.txt\", \"w\") as f:\n",
    "    f.write(prompt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0730e1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17012\n"
     ]
    }
   ],
   "source": [
    "combined_prompt = Path(\"final_prompt/combined_prompt.txt\").read_text()\n",
    "print(len(combined_prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5950967f",
   "metadata": {},
   "source": [
    "API call out \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ad20536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "func_context chars: 1327\n",
      "function_format chars: 176\n",
      "stats chars: 13637\n",
      "reasoning chars: 172\n",
      "## === APPEND NEW TRANSFORM FUNCTIONS BELOW ===\n",
      "\n",
      "\n",
      "def convert_salary_estimate_to_numeric(df):\n",
      "    \"\"\"\n",
      "    Convert the 'Salary Estimate' column to numeric values by removing the '$' and ',' characters and converting the resulting string to a float.\n",
      "\n",
      "    Args:\n",
      "        df (pd.DataFrame): The input DataFrame.\n",
      "\n",
      "    Returns:\n",
      "        tuple: A tuple containing the transformed DataFrame and a list of changes made to the DataFrame.\n",
      "    \"\"\"\n",
      "    df_out = df.copy()\n",
      "    change_log = []\n",
      "\n",
      "    # Remove the '$' and ',' characters from the 'Salary Estimate' column\n",
      "    df_out['Salary Estimate'] = df_out['Salary Estimate'].str.replace('$', '').str.replace(',', '')\n",
      "\n",
      "    # Convert the 'Salary Estimate' column to numeric values\n",
      "    df_out['Salary Estimate'] = pd.to_numeric(df_out['Salary Estimate'])\n",
      "\n",
      "    change_log.append(\"Converted 'Salary Estimate' column to numeric values\")\n",
      "\n",
      "    return df_out, change_log\n",
      "\n",
      "\n",
      "\n",
      "def extract_job_description_keywords(df):\n",
      "    \"\"\"\n",
      "    Extract keywords from the 'Job Description' column by splitting the text into individual words and counting the frequency of each word.\n",
      "\n",
      "    Args:\n",
      "        df (pd.DataFrame): The input DataFrame.\n",
      "\n",
      "    Returns:\n",
      "        tuple: A tuple containing the transformed DataFrame and a list of changes made to the DataFrame.\n",
      "    \"\"\"\n",
      "    df_out = df.copy()\n",
      "    change_log = []\n",
      "\n",
      "    # Split the 'Job Description' column into individual words\n",
      "    df_out['Job Description Keywords'] = df_out['Job Description'].apply(lambda x: x.split())\n",
      "\n",
      "    # Count the frequency of each word in the 'Job Description Keywords' column\n",
      "    df_out['Job Description Keyword Frequency'] = df_out['Job Description Keywords'].apply(lambda x: {word: x.count(word) for word in x})\n",
      "\n",
      "    change_log.append(\"Extracted keywords from 'Job Description' column\")\n",
      "\n",
      "    return df_out, change_log\n",
      "\n",
      "\n",
      "\n",
      "def encode_company_name_as_categorical(df):\n",
      "    \"\"\"\n",
      "    Encode the 'Company Name' column as categorical values using the pandas `Categorical` function.\n",
      "\n",
      "    Args:\n",
      "        df (pd.DataFrame): The input DataFrame.\n",
      "\n",
      "    Returns:\n",
      "        tuple: A tuple containing the transformed DataFrame and a list of changes made to the DataFrame.\n",
      "    \"\"\"\n",
      "    df_out = df.copy()\n",
      "    change_log = []\n",
      "\n",
      "    # Encode the 'Company Name' column as categorical values\n",
      "    df_out['Company Name'] = pd.Categorical(df_out['Company Name'])\n",
      "\n",
      "    change_log.append(\"Encoded 'Company Name' column as categorical values\")\n",
      "\n",
      "    return df_out, change_log\n",
      "\n",
      "\n",
      "\n",
      "def calculate_average_rating_by_location(df):\n",
      "    \"\"\"\n",
      "    Calculate the average rating by location by grouping the 'Rating' column by the 'Location' column and calculating the mean.\n",
      "\n",
      "    Args:\n",
      "        df (pd.DataFrame): The input DataFrame.\n",
      "\n",
      "    Returns:\n",
      "        tuple: A tuple containing the transformed DataFrame and a list of changes made to the DataFrame.\n",
      "    \"\"\"\n",
      "    df_out = df.copy()\n",
      "    change_log = []\n",
      "\n",
      "    # Group the 'Rating' column by the 'Location' column and calculate the mean\n",
      "    df_out['Average Rating by Location'] = df_out.groupby('Location')['Rating'].transform('mean')\n",
      "\n",
      "    change_log.append(\"Calculated average rating by location\")\n",
      "\n",
      "    return df_out, change_log\n",
      "\n",
      "\n",
      "\n",
      "def extract_headquarters_state(df):\n",
      "    \"\"\"\n",
      "    Extract the state from the 'Headquarters' column by splitting the text into individual words and extracting the last word.\n",
      "\n",
      "    Args:\n",
      "        df (pd.DataFrame): The input DataFrame.\n",
      "\n",
      "    Returns:\n",
      "        tuple: A tuple containing the transformed DataFrame and a list of changes made to the DataFrame.\n",
      "    \"\"\"\n",
      "    df_out = df.copy()\n",
      "    change_log = []\n",
      "\n",
      "    # Split the 'Headquarters' column into individual words\n",
      "    df_out['Headquarters State'] = df_out['Headquarters'].apply(lambda x: x.split()[-1])\n",
      "\n",
      "    change_log.append(\"Extracted state from 'Headquarters' column\")\n",
      "\n",
      "    return df_out, change_log\n",
      "\n",
      "\n",
      "\n",
      "def encode_size_as_ordinal(df):\n",
      "    \"\"\"\n",
      "    Encode the 'Size' column as ordinal values using the pandas `Categorical` function.\n",
      "\n",
      "    Args:\n",
      "        df (pd.DataFrame): The input DataFrame.\n",
      "\n",
      "    Returns:\n",
      "        tuple: A tuple containing the transformed DataFrame and a list of changes made to the DataFrame.\n",
      "    \"\"\"\n",
      "    df_out = df.copy()\n",
      "    change_log = []\n",
      "\n",
      "    # Encode the 'Size' column as ordinal values\n",
      "    df_out['Size'] = pd.Categorical(df_out['Size'], ordered=True)\n",
      "\n",
      "    change_log.append(\"Encoded 'Size' column as ordinal values\")\n",
      "\n",
      "    return df_out, change_log\n",
      "\n",
      "\n",
      "\n",
      "def calculate_founded_year(df):\n",
      "    \"\"\"\n",
      "    Calculate the year the company was founded by extracting the year from the 'Founded' column.\n",
      "\n",
      "    Args:\n",
      "        df (pd.DataFrame): The input DataFrame.\n",
      "\n",
      "    Returns:\n",
      "        tuple: A tuple containing the transformed DataFrame and a list of changes made to the DataFrame.\n",
      "    \"\"\"\n",
      "    df_out = df.copy()\n",
      "    change_log = []\n",
      "\n",
      "    # Extract the year from the 'Founded' column\n",
      "    df_out\n"
     ]
    }
   ],
   "source": [
    "from cerebras.cloud.sdk import Cerebras\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "client = Cerebras(api_key=os.environ[\"CEREBRAS_API_KEY\"])\n",
    "\n",
    "# --- Load files ---\n",
    "func_test_suite = Path(\"frameworks/func_test_suite.txt\").read_text()\n",
    "function_format = Path(\"frameworks/function_format.txt\").read_text()\n",
    "stats = Path(\"outputs/stats.txt\").read_text()\n",
    "reasoning = Path(\"frameworks/reasoning.txt\").read_text()\n",
    "\n",
    "# --- Trim func_test_suite ---\n",
    "marker = \"=== APPEND NEW TRANSFORM FUNCTIONS BELOW ===\"\n",
    "head, _, tail = func_test_suite.partition(marker)\n",
    "tail_lines = tail.splitlines()[-200:]\n",
    "\n",
    "func_context = (\n",
    "    head\n",
    "    + marker\n",
    "    + \"\\n\"\n",
    "    + \"\\n\".join(tail_lines)\n",
    ")\n",
    "\n",
    "# --- System prompt (rules only) ---\n",
    "system_prompt = f\"\"\"\n",
    "You are an expert Python developer.\n",
    "\n",
    "You are operating in APPEND-ONLY mode.\n",
    "\n",
    "Rules:\n",
    "- You MUST NOT modify text above the append marker.\n",
    "- You MAY ONLY append new standalone functions.\n",
    "- Preserve spacing, comments, and formatting.\n",
    "- Each function must operate on a copy of a DataFrame.\n",
    "- Leave two blank lines between appended functions.\n",
    "\n",
    "The contents of func_test_suite.txt are authoritative.\n",
    "\"\"\"\n",
    "\n",
    "# --- User prompt (variable content) ---\n",
    "user_prompt = f\"\"\"\n",
    "Here is the current state of the test suite:\n",
    "\n",
    "{func_context}\n",
    "\n",
    "You MUST follow this function format:\n",
    "\n",
    "{function_format}\n",
    "\n",
    "Here are the dataset statistics:\n",
    "\n",
    "{stats}\n",
    "\n",
    "Use reasoning guidance from:\n",
    "\n",
    "{reasoning}\n",
    "\n",
    "Proceed.\n",
    "\"\"\"\n",
    "\n",
    "print(\"func_context chars:\", len(func_context))\n",
    "print(\"function_format chars:\", len(function_format))\n",
    "print(\"stats chars:\", len(stats))\n",
    "print(\"reasoning chars:\", len(reasoning))\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"llama-3.3-70b\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ],\n",
    "    max_completion_tokens=1024,\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7743737",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9535e3d7",
   "metadata": {},
   "source": [
    "Write out results from LLM:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
