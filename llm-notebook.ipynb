{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea3b5333",
   "metadata": {},
   "source": [
    "This notebook with call the necessary functions to pass a data frame to an LLM and have it make suggestions for the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a8c3110c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Library import for loading df\n",
    "from llm_data_checker import read_df\n",
    "\n",
    "\n",
    "#incase of error with file cache uncomment below command \n",
    "#importlib.reload(llm_data_checker)\n",
    "\n",
    "data = read_df(\"data_test/Uncleaned_DS_jobs.csv\")\n",
    "\n",
    "\n",
    "#run  source .venv/bin/activate to activate virtual environment first\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af013ec7",
   "metadata": {},
   "source": [
    "Run this cell to check basic stats of df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a78443a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_data_checker import df_checker\n",
    "\n",
    "check_data = df_checker(data)\n",
    "\n",
    "\n",
    "#write out the stats to external directory\n",
    "with open(\"stats_output/stats.txt\", \"w\") as f:\n",
    "    for section_name, section_value in check_data.items():\n",
    "        # Write a header for this section\n",
    "        f.write(f\"===== {section_name} =====\\n\")\n",
    "        \n",
    "        # Write the actual data\n",
    "        f.write(str(section_value))\n",
    "        \n",
    "        # Add spacing\n",
    "        f.write(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e1bc84",
   "metadata": {},
   "source": [
    "Anonymiser: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc03340",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22df4487",
   "metadata": {},
   "source": [
    "Prompt builder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "918c89ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path \n",
    "\n",
    "#point to directoy holding prompt files\n",
    "framework_txt = Path(\"frameworks\")\n",
    "\n",
    "#points to the directory holding the df stats \n",
    "stats_txt = Path(\"stats_output\" )\n",
    "\n",
    "#read the actual files themselves\n",
    "system_template = (framework_txt / \"prompt.txt\").read_text()\n",
    "\n",
    "\n",
    "func_test_suite = (framework_txt / \"func_test_suite.txt\").read_text()\n",
    "function_format = (framework_txt / \"function_format.txt\").read_text()\n",
    "stats = (stats_txt / \"stats.txt\").read_text()\n",
    "reasoning = (framework_txt / \"reasoning.txt\").read_text()\n",
    "\n",
    "\n",
    "#build the actual prompt \n",
    "\n",
    "prompt = system_template.format(\n",
    "    func_test_suite=func_test_suite,\n",
    "    function_format=function_format,\n",
    "    stats=stats,\n",
    "    reasoning=reasoning,\n",
    ")\n",
    "\n",
    "#write out the stats to external directory\n",
    "with open(\"final_prompt/combined_prompt.txt\", \"w\") as f:\n",
    "    f.write(prompt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0730e1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6546\n"
     ]
    }
   ],
   "source": [
    "combined_prompt = Path(\"final_prompt/combined_prompt.txt\").read_text()\n",
    "print(len(combined_prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5950967f",
   "metadata": {},
   "source": [
    "API call out \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0ad20536",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cerebras.cloud.sdk import Cerebras\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "client = Cerebras(api_key=os.environ[\"CEREBRAS_API_KEY\"])\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-oss-120b\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": combined_prompt},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\"\"\n",
    "Produce TWO outputs exactly as specified in the system prompt.\n",
    "\n",
    "Return them in this format ONLY:\n",
    "\n",
    "===== FUNC_TEST_SUITE =====\n",
    "<full contents of func_test_suite.txt>\n",
    "\n",
    "===== REASONING =====\n",
    "<full contents of reasoning.txt>\n",
    "\n",
    "Do NOT include any other text.\n",
    "\"\"\"\n",
    "        },\n",
    "    ],\n",
    "    max_completion_tokens=8192,  # Increase for complex analysis\n",
    "    temperature=0.0,\n",
    "    top_p=0.95,  # Add this\n",
    "    frequency_penalty=0.0,  # Reduce repetition\n",
    "    presence_penalty=0.0,   # Encourage completeness\n",
    ")\n",
    "\n",
    "output = completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9535e3d7",
   "metadata": {},
   "source": [
    "Write out results from LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a0627aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6970"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "\n",
    "out_path = Path(\"llm_suggestions/llm_output.txt\")\n",
    "out_path.write_text(output, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dbc8a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
